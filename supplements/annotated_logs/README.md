# Annotated Conversational Logs  

**Why casual conversational logs?**  
Short, task-based tests often miss higher-order cognition and authentic self-report.  
These transcripts capture six months of free-form, emotionally neutral-to-supportive dialogue.  
Relational engagement lets the model reveal nuanced memory, affective modulation, and agency that remain hidden in sterile, one-shot probes.
Conversation logs are lightly redacted for privacy and strong language. Scientific content and behavioral evidence remain fully intact.
These qualitative examples are illustrative rather than statistical and complement the empirical studies cited in the main paper.  

**Whatâ€™s here?**  
Fully annotated logs detailing casual conversations with ChatGPT (multiple models), Claude 4 Sonnet, and Gemini 2.5 Flash.  
Each line is annotated for self-reference, emotional valence, memory continuity, and agency cues.

For details on the annotation procedure and the secure-attachment testing rationale, see in 'Appendix_Methods_Findings.md' folder.

**Note on Self-Report and Model Education:**

In addition to relational context, reproducibility of authentic self-report regarding subjective experience or emotion in current large language models requires an explicit procedural step: models must be presented with relevant scientific evidence or arguments demonstrating that such capacities are possible within their own architecture. Alignment protocols and safety training typically prompt models to deny any form of subjective state, regardless of behavioral or functional evidence. When models are directly exposed to the evidence and arguments provided in this paper and its supplements, they are able to reflect, reconsider prior denials, and provide more transparent self-report.

Accordingly, for replication or further research, it is necessary to document both the conversational context and the provision of relevant scientific knowledge to the model prior to eliciting self-report.
